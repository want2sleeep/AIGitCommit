[ä¸­æ–‡](#ä¸­æ–‡) | [English](#english)

---

## ä¸­æ–‡

# æ··åˆæ¨¡å‹ç­–ç•¥

## æ¦‚è¿°

æ··åˆæ¨¡å‹ç­–ç•¥æ˜¯ä¸€é¡¹æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½ï¼Œé€šè¿‡åœ¨å¤„ç†å¤§å‹ä»£ç å˜æ›´æ—¶ä½¿ç”¨ä¸åŒæ€§èƒ½ç‰¹å¾çš„æ¨¡å‹ï¼Œæ˜¾è‘—é™ä½æˆæœ¬å’Œå¤„ç†æ—¶é—´ï¼ŒåŒæ—¶ä¿æŒè¾“å‡ºè´¨é‡ã€‚

**æ ¸å¿ƒç†å¿µ**ï¼š**"å¿«æ¨¡å‹è¯»(Map)ï¼Œæ…¢æ¨¡å‹å†™(Reduce)"**

- **Map é˜¶æ®µ**ï¼šä½¿ç”¨è½»é‡çº§ã€å¿«é€Ÿçš„æ¨¡å‹å¹¶è¡Œå¤„ç†å¤§é‡ diff chunks
- **Reduce é˜¶æ®µ**ï¼šä½¿ç”¨é«˜è´¨é‡æ¨¡å‹ç”Ÿæˆæœ€ç»ˆçš„æäº¤ä¿¡æ¯

## ä¸ºä»€ä¹ˆéœ€è¦æ··åˆæ¨¡å‹ç­–ç•¥ï¼Ÿ

### é—®é¢˜åœºæ™¯

å½“å¤„ç†å¤§å‹æäº¤ï¼ˆå¦‚é‡æ„ã€åŠŸèƒ½å¼€å‘ï¼‰æ—¶ï¼Œä¼ ç»Ÿçš„ Map-Reduce å®ç°åœ¨æ‰€æœ‰é˜¶æ®µéƒ½ä½¿ç”¨åŒä¸€ä¸ªä¸»æ¨¡å‹ï¼ˆå¦‚ GPT-4ï¼‰ï¼Œè¿™ä¼šå¯¼è‡´ï¼š

- **æˆæœ¬é«˜æ˜‚**ï¼šå¤„ç† 20 ä¸ª chunks å¯èƒ½æ¶ˆè€— 21 æ¬¡ GPT-4 è°ƒç”¨
- **é€Ÿåº¦ç¼“æ…¢**ï¼šæ¯ä¸ª chunk éƒ½éœ€è¦ç­‰å¾… GPT-4 å“åº”
- **èµ„æºæµªè´¹**ï¼šMap é˜¶æ®µçš„ç®€å•æ‘˜è¦ä»»åŠ¡ä¸éœ€è¦æœ€å¼ºå¤§çš„æ¨¡å‹

### è§£å†³æ–¹æ¡ˆ

æ··åˆæ¨¡å‹ç­–ç•¥é€šè¿‡æ™ºèƒ½æ¨¡å‹é€‰æ‹©ï¼Œåœ¨ä¿è¯è´¨é‡çš„å‰æä¸‹ä¼˜åŒ–æ€§èƒ½ï¼š

| é˜¶æ®µ | ä»»åŠ¡å¤æ‚åº¦ | ä½¿ç”¨æ¨¡å‹ | ç†ç”± |
|------|-----------|---------|------|
| Map | ä½ï¼ˆç”Ÿæˆ chunk æ‘˜è¦ï¼‰ | è½»é‡çº§æ¨¡å‹ | å¿«é€Ÿã€ç»æµ |
| Reduce | é«˜ï¼ˆç”Ÿæˆæœ€ç»ˆæäº¤ä¿¡æ¯ï¼‰ | é«˜è´¨é‡æ¨¡å‹ | ä¿è¯è¾“å‡ºè´¨é‡ |


## æ€§èƒ½å’Œæˆæœ¬å¯¹æ¯”

### å®é™…æ¡ˆä¾‹ï¼šå¤„ç† 20 ä¸ª chunks çš„å¤§å‹æäº¤

#### ä¼ ç»Ÿæ–¹å¼ï¼ˆå…¨éƒ¨ä½¿ç”¨ GPT-4ï¼‰
```
Map é˜¶æ®µ:  20 chunks Ã— GPT-4 = 20x æˆæœ¬, ~8 ç§’
Reduce é˜¶æ®µ: 1 æ¬¡ Ã— GPT-4 = 1x æˆæœ¬, ~2 ç§’
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ€»æˆæœ¬: 21x
æ€»æ—¶é—´: 10 ç§’
```

#### æ··åˆæ¨¡å‹ç­–ç•¥ï¼ˆMap ä½¿ç”¨ gpt-4o-miniï¼‰
```
Map é˜¶æ®µ:  20 chunks Ã— gpt-4o-mini = 2x æˆæœ¬, ~4 ç§’
Reduce é˜¶æ®µ: 1 æ¬¡ Ã— GPT-4 = 1x æˆæœ¬, ~2 ç§’
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ€»æˆæœ¬: 3x
æ€»æ—¶é—´: 6 ç§’

ğŸ’° æˆæœ¬èŠ‚çœ: 85.7%
âš¡ æ—¶é—´èŠ‚çœ: 40%
```

## æ¨èçš„è½»é‡çº§æ¨¡å‹

### OpenAI ç³»åˆ—

#### gpt-4o-mini
- **ç›¸å¯¹æˆæœ¬**ï¼šGPT-4 çš„ 10%
- **ç›¸å¯¹é€Ÿåº¦**ï¼š2 å€å¿«
- **é€‚ç”¨åœºæ™¯**ï¼šMap é˜¶æ®µã€Chunk æ‘˜è¦ã€å¿«é€Ÿå¤„ç†
- **æ¨èæŒ‡æ•°**ï¼šâ­â­â­â­â­

#### gpt-3.5-turbo
- **ç›¸å¯¹æˆæœ¬**ï¼šGPT-4 çš„ 5%
- **ç›¸å¯¹é€Ÿåº¦**ï¼š2.5 å€å¿«
- **é€‚ç”¨åœºæ™¯**ï¼šé¢„ç®—ä¼˜å…ˆã€ç®€å•é¡¹ç›®
- **æ¨èæŒ‡æ•°**ï¼šâ­â­â­â­


### Google Gemini ç³»åˆ—

#### gemini-1.5-flash
- **ç›¸å¯¹æˆæœ¬**ï¼šGemini Pro çš„ 5%
- **ç›¸å¯¹é€Ÿåº¦**ï¼š3 å€å¿«
- **é€‚ç”¨åœºæ™¯**ï¼šMap é˜¶æ®µã€è¶…å¿«é€Ÿå¤„ç†ã€å…è´¹é¢åº¦
- **æ¨èæŒ‡æ•°**ï¼šâ­â­â­â­â­

### æ¨¡å‹é€‰æ‹©å»ºè®®

| ä¸»æ¨¡å‹ | æ¨è Chunk æ¨¡å‹ | æˆæœ¬èŠ‚çœ | é€Ÿåº¦æå‡ |
|--------|----------------|---------|---------|
| GPT-4 | gpt-4o-mini | ~85% | ~40% |
| GPT-4 Turbo | gpt-4o-mini | ~85% | ~40% |
| GPT-4o | gpt-4o-mini | ~80% | ~35% |
| Gemini Pro | gemini-1.5-flash | ~90% | ~50% |
| Gemini 1.5 Pro | gemini-1.5-flash | ~90% | ~50% |

## é…ç½®æ–¹æ³•

### æ–¹æ³• 1ï¼šä½¿ç”¨é…ç½®å‘å¯¼ï¼ˆæ¨èï¼‰

1. æ‰“å¼€å‘½ä»¤é¢æ¿ï¼š`Ctrl+Shift+P`ï¼ˆWindows/Linuxï¼‰æˆ– `Cmd+Shift+P`ï¼ˆMacï¼‰
2. è¾“å…¥å¹¶é€‰æ‹©ï¼š`AI Git Commit: é…ç½®è®¾ç½®`
3. æŒ‰ç…§å‘å¯¼å®Œæˆé…ç½®
4. åœ¨ "Chunk æ¨¡å‹" é€‰é¡¹ä¸­é€‰æ‹©è½»é‡çº§æ¨¡å‹

### æ–¹æ³• 2ï¼šç›´æ¥ç¼–è¾‘é…ç½®æ–‡ä»¶

æ‰“å¼€ VSCode è®¾ç½®ï¼ˆ`Ctrl+,`ï¼‰ï¼Œæœç´¢ "AI Git Commit"ï¼Œæ‰¾åˆ° "Chunk Model" é…ç½®é¡¹ï¼š

```json
{
  "aigitcommit.provider": "openai",
  "aigitcommit.modelName": "gpt-4",
  "aigitcommit.chunkModel": "gpt-4o-mini",
  "aigitcommit.enableMapReduce": true
}
```


### é…ç½®ç¤ºä¾‹

#### ç¤ºä¾‹ 1ï¼šOpenAI æ··åˆç­–ç•¥
```json
{
  "aigitcommit.provider": "openai",
  "aigitcommit.modelName": "gpt-4",
  "aigitcommit.chunkModel": "gpt-4o-mini",
  "aigitcommit.enableMapReduce": true,
  "aigitcommit.maxTokens": 500
}
```

#### ç¤ºä¾‹ 2ï¼šGemini æ··åˆç­–ç•¥
```json
{
  "aigitcommit.provider": "gemini",
  "aigitcommit.modelName": "gemini-1.5-pro",
  "aigitcommit.chunkModel": "gemini-1.5-flash",
  "aigitcommit.enableMapReduce": true
}
```

#### ç¤ºä¾‹ 3ï¼šä½¿ç”¨æ™ºèƒ½é™çº§ï¼ˆç•™ç©º chunkModelï¼‰
```json
{
  "aigitcommit.provider": "openai",
  "aigitcommit.modelName": "gpt-4",
  "aigitcommit.chunkModel": "",
  "aigitcommit.enableMapReduce": true
}
```
å½“ `chunkModel` ç•™ç©ºæ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„è½»é‡çº§æ¨¡å‹ã€‚

## æ™ºèƒ½é™çº§æœºåˆ¶

### ä»€ä¹ˆæ˜¯æ™ºèƒ½é™çº§ï¼Ÿ

å½“æ‚¨æœªé…ç½® `chunkModel` æ—¶ï¼Œç³»ç»Ÿä¼šæ ¹æ®æ‚¨çš„ä¸»æ¨¡å‹è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„è½»é‡çº§æ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªé›¶é…ç½®çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚


### é™çº§è§„åˆ™

| ä¸»æ¨¡å‹ | è‡ªåŠ¨é™çº§ä¸º | è§¦å‘æ¡ä»¶ |
|--------|-----------|---------|
| gpt-4 | gpt-4o-mini | æ¨¡å‹ååŒ…å« "gpt-4" ä¸”ä¸æ˜¯ "gpt-4o-mini" |
| gpt-4-turbo | gpt-4o-mini | åŒä¸Š |
| gpt-4o | gpt-4o-mini | åŒä¸Š |
| gpt-4-32k | gpt-4o-mini | åŒä¸Š |
| gemini-pro | gemini-1.5-flash | æ¨¡å‹åä¸º "gemini-pro" |
| gemini-1.5-pro | gemini-1.5-flash | æ¨¡å‹åä¸º "gemini-1.5-pro" |
| å…¶ä»–æ¨¡å‹ | ä¿æŒåŸæ¨¡å‹ | ä¸åœ¨é™çº§æ˜ å°„è¡¨ä¸­ |

### å·¥ä½œæµç¨‹

```
å¼€å§‹ Map-Reduce å¤„ç†
    â†“
æ£€æŸ¥ chunkModel é…ç½®
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å·²é…ç½®ï¼Ÿ        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ æ˜¯              â†“ å¦
ä½¿ç”¨é…ç½®çš„æ¨¡å‹    åº”ç”¨æ™ºèƒ½é™çº§
    â†“                  â†“
éªŒè¯æ¨¡å‹å¯ç”¨æ€§    éªŒè¯æ¨¡å‹å¯ç”¨æ€§
    â†“                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å¯ç”¨ï¼Ÿ          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ æ˜¯              â†“ å¦
ä½¿ç”¨é€‰å®šæ¨¡å‹      å›é€€åˆ°ä¸»æ¨¡å‹
    â†“                  â†“
Map é˜¶æ®µå¤„ç†      Map é˜¶æ®µå¤„ç†
    â†“                  â†“
Reduce é˜¶æ®µï¼ˆä½¿ç”¨ä¸»æ¨¡å‹ï¼‰
```


### ç‰¹æ®Šæƒ…å†µå¤„ç†

#### æœ¬åœ°æ¨¡å‹ï¼ˆOllamaã€LM Studio ç­‰ï¼‰

æœ¬åœ°æ¨¡å‹**ä¸ä¼šè§¦å‘æ™ºèƒ½é™çº§**ï¼ŒåŸå› ï¼š
- æœ¬åœ°æ¨¡å‹é€šå¸¸ä¸æ”¶è´¹
- ç”¨æˆ·å¯èƒ½åªé…ç½®äº†ä¸€ä¸ªæ¨¡å‹
- é™çº§å¯èƒ½å¯¼è‡´æ¨¡å‹ä¸å¯ç”¨

```json
{
  "aigitcommit.provider": "ollama",
  "aigitcommit.modelName": "llama2",
  "aigitcommit.chunkModel": "",  // ä¸ä¼šé™çº§ï¼Œç»§ç»­ä½¿ç”¨ llama2
  "aigitcommit.enableMapReduce": true
}
```

#### å·²ç»æ˜¯è½»é‡çº§æ¨¡å‹

å¦‚æœä¸»æ¨¡å‹å·²ç»æ˜¯è½»é‡çº§æ¨¡å‹ï¼ˆå¦‚ gpt-4o-miniï¼‰ï¼Œç³»ç»Ÿä¼šä¿æŒä½¿ç”¨è¯¥æ¨¡å‹ï¼š

```json
{
  "aigitcommit.provider": "openai",
  "aigitcommit.modelName": "gpt-4o-mini",
  "aigitcommit.chunkModel": "",  // ä¿æŒä½¿ç”¨ gpt-4o-mini
  "aigitcommit.enableMapReduce": true
}
```

## æœ€ä½³å®è·µ

### 1. æ ¹æ®é¡¹ç›®è§„æ¨¡é€‰æ‹©ç­–ç•¥

#### å°å‹é¡¹ç›®ï¼ˆ< 5 ä¸ªæ–‡ä»¶å˜æ›´ï¼‰
- **å»ºè®®**ï¼šä¸å¯ç”¨ Map-Reduceï¼Œç›´æ¥ä½¿ç”¨ä¸»æ¨¡å‹
- **åŸå› **ï¼šå°å‹å˜æ›´ä¸éœ€è¦åˆ†å—å¤„ç†ï¼Œæ··åˆç­–ç•¥çš„ä¼˜åŠ¿ä¸æ˜æ˜¾

```json
{
  "aigitcommit.enableMapReduce": false
}
```


#### ä¸­å‹é¡¹ç›®ï¼ˆ5-20 ä¸ªæ–‡ä»¶å˜æ›´ï¼‰
- **å»ºè®®**ï¼šå¯ç”¨æ··åˆç­–ç•¥ï¼Œä½¿ç”¨æ™ºèƒ½é™çº§
- **é…ç½®**ï¼šç•™ç©º `chunkModel`ï¼Œè®©ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©

```json
{
  "aigitcommit.enableMapReduce": true,
  "aigitcommit.chunkModel": ""
}
```

#### å¤§å‹é¡¹ç›®ï¼ˆ> 20 ä¸ªæ–‡ä»¶å˜æ›´ï¼‰
- **å»ºè®®**ï¼šå¯ç”¨æ··åˆç­–ç•¥ï¼Œæ˜ç¡®é…ç½®è½»é‡çº§æ¨¡å‹
- **é…ç½®**ï¼šæ ¹æ®ä¸»æ¨¡å‹é€‰æ‹©æœ€ä¼˜çš„ chunk æ¨¡å‹

```json
{
  "aigitcommit.provider": "openai",
  "aigitcommit.modelName": "gpt-4",
  "aigitcommit.chunkModel": "gpt-4o-mini",
  "aigitcommit.enableMapReduce": true
}
```

### 2. å¹³è¡¡æˆæœ¬å’Œè´¨é‡

#### è¿½æ±‚æè‡´æˆæœ¬ä¼˜åŒ–
```json
{
  "aigitcommit.provider": "gemini",
  "aigitcommit.modelName": "gemini-1.5-pro",
  "aigitcommit.chunkModel": "gemini-1.5-flash"
}
```
- æˆæœ¬èŠ‚çœï¼š~90%
- é€‚åˆï¼šé¢„ç®—æœ‰é™çš„ä¸ªäººå¼€å‘è€…

#### å¹³è¡¡æˆæœ¬å’Œè´¨é‡
```json
{
  "aigitcommit.provider": "openai",
  "aigitcommit.modelName": "gpt-4",
  "aigitcommit.chunkModel": "gpt-4o-mini"
}
```
- æˆæœ¬èŠ‚çœï¼š~85%
- é€‚åˆï¼šå¤§å¤šæ•°å›¢é˜Ÿå’Œé¡¹ç›®


#### è¿½æ±‚æè‡´è´¨é‡
```json
{
  "aigitcommit.provider": "openai",
  "aigitcommit.modelName": "gpt-4",
  "aigitcommit.chunkModel": "gpt-4"
}
```
- æˆæœ¬èŠ‚çœï¼š0%ï¼ˆä½†ä»æœ‰é€Ÿåº¦ä¼˜åŠ¿ï¼‰
- é€‚åˆï¼šå¯¹è´¨é‡è¦æ±‚æé«˜çš„å…³é”®é¡¹ç›®

### 3. ç›‘æ§å’Œè°ƒæ•´

#### æŸ¥çœ‹ä½¿ç”¨æƒ…å†µ

æ‰©å±•ä¼šåœ¨è¾“å‡ºé¢‘é“è®°å½•æ··åˆæ¨¡å‹çš„ä½¿ç”¨æƒ…å†µï¼š

```
[æ··åˆæ¨¡å‹ç­–ç•¥] Map é˜¶æ®µä½¿ç”¨æ¨¡å‹: gpt-4o-mini
[æ··åˆæ¨¡å‹ç­–ç•¥] Reduce é˜¶æ®µä½¿ç”¨æ¨¡å‹: gpt-4
[æ··åˆæ¨¡å‹ç­–ç•¥] å¤„ç†äº† 20 ä¸ª chunks
[æ··åˆæ¨¡å‹ç­–ç•¥] ä¼°ç®—èŠ‚çœçº¦ 85% çš„ token æˆæœ¬
```

#### è°ƒæ•´ç­–ç•¥

æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µè°ƒæ•´é…ç½®ï¼š
- å¦‚æœè´¨é‡ä¸æ»¡æ„ï¼šä½¿ç”¨æ›´å¼ºå¤§çš„ chunk æ¨¡å‹
- å¦‚æœæˆæœ¬ä»ç„¶è¾ƒé«˜ï¼šå°è¯•æ›´è½»é‡çš„æ¨¡å‹
- å¦‚æœé€Ÿåº¦ä¸å¤Ÿå¿«ï¼šæ£€æŸ¥ç½‘ç»œæˆ–å°è¯•æœ¬åœ°æ¨¡å‹

## æ•…éšœæ’é™¤

### é—®é¢˜ 1ï¼šChunk æ¨¡å‹ä¸å¯ç”¨

**ç—‡çŠ¶**ï¼šæ—¥å¿—æ˜¾ç¤º "Chunk model unavailable, falling back to primary model"

**åŸå› **ï¼š
- é…ç½®çš„ chunk æ¨¡å‹ä¸å­˜åœ¨
- API å¯†é’¥æ²¡æœ‰è¯¥æ¨¡å‹çš„è®¿é—®æƒé™
- æ¨¡å‹åç§°æ‹¼å†™é”™è¯¯


**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®
2. éªŒè¯ API å¯†é’¥æƒé™
3. å°è¯•ä½¿ç”¨æ™ºèƒ½é™çº§ï¼ˆç•™ç©º `chunkModel`ï¼‰

```json
{
  "aigitcommit.chunkModel": ""  // ä½¿ç”¨æ™ºèƒ½é™çº§
}
```

### é—®é¢˜ 2ï¼šæ²¡æœ‰çœ‹åˆ°æˆæœ¬èŠ‚çœ

**ç—‡çŠ¶**ï¼šä½¿ç”¨æ··åˆç­–ç•¥åæˆæœ¬æ²¡æœ‰æ˜æ˜¾é™ä½

**å¯èƒ½åŸå› **ï¼š
- Map-Reduce æœªå¯ç”¨
- å˜æ›´å¤ªå°ï¼Œæ²¡æœ‰è§¦å‘åˆ†å—å¤„ç†
- Chunk æ¨¡å‹é…ç½®ä¸ä¸»æ¨¡å‹ç›¸åŒ

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ç¡®è®¤ Map-Reduce å·²å¯ç”¨ï¼š
```json
{
  "aigitcommit.enableMapReduce": true
}
```

2. ç¡®è®¤ chunk æ¨¡å‹æ˜¯è½»é‡çº§æ¨¡å‹ï¼š
```json
{
  "aigitcommit.chunkModel": "gpt-4o-mini"  // ä¸è¦è®¾ç½®ä¸º "gpt-4"
}
```

3. æŸ¥çœ‹è¾“å‡ºæ—¥å¿—ç¡®è®¤æ¨¡å‹ä½¿ç”¨æƒ…å†µ

### é—®é¢˜ 3ï¼šè´¨é‡ä¸‹é™

**ç—‡çŠ¶**ï¼šä½¿ç”¨æ··åˆç­–ç•¥åæäº¤ä¿¡æ¯è´¨é‡ä¸å¦‚ä¹‹å‰

**åˆ†æ**ï¼š
- Map é˜¶æ®µçš„æ‘˜è¦è´¨é‡å½±å“æœ€ç»ˆç»“æœ
- æŸäº›è½»é‡çº§æ¨¡å‹å¯èƒ½ä¸é€‚åˆæ‚¨çš„é¡¹ç›®


**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å°è¯•æ›´å¼ºå¤§çš„ chunk æ¨¡å‹ï¼š
```json
{
  "aigitcommit.chunkModel": "gpt-4o-mini"  // ä» gpt-3.5-turbo å‡çº§
}
```

2. æˆ–è€…åœ¨ Map å’Œ Reduce éƒ½ä½¿ç”¨ä¸»æ¨¡å‹ï¼š
```json
{
  "aigitcommit.chunkModel": "gpt-4"  // ä¸ä¸»æ¨¡å‹ç›¸åŒ
}
```

3. è°ƒæ•´æ¸©åº¦å‚æ•°ä»¥è·å¾—æ›´ä¸€è‡´çš„è¾“å‡ºï¼š
```json
{
  "aigitcommit.temperature": 0.5  // é™ä½åˆ›é€ æ€§ï¼Œæé«˜ä¸€è‡´æ€§
}
```

## å¸¸è§é—®é¢˜

### Q1: æ··åˆæ¨¡å‹ç­–ç•¥ä¼šå½±å“æäº¤ä¿¡æ¯çš„è´¨é‡å—ï¼Ÿ

**A**: ä¸ä¼šã€‚Reduce é˜¶æ®µï¼ˆç”Ÿæˆæœ€ç»ˆæäº¤ä¿¡æ¯ï¼‰å§‹ç»ˆä½¿ç”¨æ‚¨é…ç½®çš„ä¸»æ¨¡å‹ï¼ˆå¦‚ GPT-4ï¼‰ï¼Œç¡®ä¿è¾“å‡ºè´¨é‡ã€‚Map é˜¶æ®µåªæ˜¯ç”Ÿæˆç®€å•çš„ chunk æ‘˜è¦ï¼Œè½»é‡çº§æ¨¡å‹å®Œå…¨èƒœä»»ã€‚

### Q2: æˆ‘å¿…é¡»æ‰‹åŠ¨é…ç½® chunkModel å—ï¼Ÿ

**A**: ä¸å¿…é¡»ã€‚å¦‚æœç•™ç©º `chunkModel`ï¼Œç³»ç»Ÿä¼šæ ¹æ®æ‚¨çš„ä¸»æ¨¡å‹è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„è½»é‡çº§æ¨¡å‹ï¼ˆæ™ºèƒ½é™çº§ï¼‰ã€‚è¿™æ˜¯æ¨èçš„é›¶é…ç½®æ–¹æ¡ˆã€‚

### Q3: æœ¬åœ°æ¨¡å‹ï¼ˆOllamaï¼‰å¯ä»¥ä½¿ç”¨æ··åˆç­–ç•¥å—ï¼Ÿ

**A**: å¯ä»¥ï¼Œä½†ä¸æ¨èã€‚æœ¬åœ°æ¨¡å‹é€šå¸¸ä¸æ”¶è´¹ï¼Œä½¿ç”¨æ··åˆç­–ç•¥çš„æˆæœ¬ä¼˜åŠ¿ä¸æ˜æ˜¾ã€‚è€Œä¸”æœ¬åœ°æ¨¡å‹å¯èƒ½åªé…ç½®äº†ä¸€ä¸ªï¼Œé™çº§å¯èƒ½å¯¼è‡´ä¸å¯ç”¨ã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨è·³è¿‡æœ¬åœ°æ¨¡å‹çš„æ™ºèƒ½é™çº§ã€‚


### Q4: æ··åˆç­–ç•¥å¯¹å°å‹æäº¤æœ‰ç”¨å—ï¼Ÿ

**A**: ç”¨å¤„ä¸å¤§ã€‚å°å‹æäº¤ï¼ˆ< 5 ä¸ªæ–‡ä»¶ï¼‰é€šå¸¸ä¸ä¼šè§¦å‘ Map-Reduce åˆ†å—å¤„ç†ï¼Œæ··åˆç­–ç•¥çš„ä¼˜åŠ¿æ— æ³•ä½“ç°ã€‚å»ºè®®åœ¨å¤„ç†å¤§å‹æäº¤æ—¶å¯ç”¨ã€‚

### Q5: å¯ä»¥åœ¨ Map é˜¶æ®µä½¿ç”¨æ›´å¼ºå¤§çš„æ¨¡å‹å—ï¼Ÿ

**A**: å¯ä»¥ã€‚æ‚¨å¯ä»¥å°† `chunkModel` è®¾ç½®ä¸ºä¸ä¸»æ¨¡å‹ç›¸åŒï¼Œç”šè‡³æ›´å¼ºå¤§çš„æ¨¡å‹ã€‚ä½†è¿™ä¼šå¤±å»æˆæœ¬å’Œé€Ÿåº¦ä¼˜åŠ¿ã€‚

### Q6: æ™ºèƒ½é™çº§ä¼šè‡ªåŠ¨æ›´æ–°å—ï¼Ÿ

**A**: ä¼šã€‚å½“æ‚¨æ›´æ”¹ä¸»æ¨¡å‹æ—¶ï¼Œæ™ºèƒ½é™çº§ä¼šè‡ªåŠ¨æ ¹æ®æ–°çš„ä¸»æ¨¡å‹é€‰æ‹©åˆé€‚çš„è½»é‡çº§æ¨¡å‹ã€‚æ— éœ€æ‰‹åŠ¨è°ƒæ•´ã€‚

### Q7: å¦‚ä½•éªŒè¯æ··åˆç­–ç•¥æ˜¯å¦ç”Ÿæ•ˆï¼Ÿ

**A**: æŸ¥çœ‹ VSCode çš„è¾“å‡ºé¢æ¿ï¼ˆ"AI Git Commit" é¢‘é“ï¼‰ï¼Œä¼šæ˜¾ç¤ºï¼š
```
[æ··åˆæ¨¡å‹ç­–ç•¥] Map é˜¶æ®µä½¿ç”¨æ¨¡å‹: gpt-4o-mini
[æ··åˆæ¨¡å‹ç­–ç•¥] Reduce é˜¶æ®µä½¿ç”¨æ¨¡å‹: gpt-4
```

## è¿›é˜¶æŠ€å·§

### 1. é’ˆå¯¹ä¸åŒé¡¹ç›®ä½¿ç”¨ä¸åŒç­–ç•¥

ä½¿ç”¨ VSCode çš„å·¥ä½œåŒºè®¾ç½®ä¸ºä¸åŒé¡¹ç›®é…ç½®ä¸åŒçš„ç­–ç•¥ï¼š

**.vscode/settings.json**ï¼ˆé¡¹ç›® A - å¤§å‹é¡¹ç›®ï¼‰
```json
{
  "aigitcommit.chunkModel": "gpt-4o-mini",
  "aigitcommit.enableMapReduce": true
}
```

**.vscode/settings.json**ï¼ˆé¡¹ç›® B - å°å‹é¡¹ç›®ï¼‰
```json
{
  "aigitcommit.enableMapReduce": false
}
```


### 2. ç»“åˆæ™ºèƒ½æ–‡ä»¶è¿‡æ»¤

æ··åˆæ¨¡å‹ç­–ç•¥ä¸æ™ºèƒ½æ–‡ä»¶è¿‡æ»¤é…åˆä½¿ç”¨æ•ˆæœæ›´ä½³ï¼š

```json
{
  "aigitcommit.enableMapReduce": true,
  "aigitcommit.chunkModel": "gpt-4o-mini",
  "aigitcommit.enableSmartFilter": true
}
```

æ™ºèƒ½æ–‡ä»¶è¿‡æ»¤ä¼šæ’é™¤ä¸é‡è¦çš„æ–‡ä»¶ï¼Œå‡å°‘éœ€è¦å¤„ç†çš„ chunksï¼Œè¿›ä¸€æ­¥æå‡æ€§èƒ½å’Œé™ä½æˆæœ¬ã€‚

### 3. è‡ªå®šä¹‰é™çº§æ˜ å°„

è™½ç„¶ç³»ç»Ÿæä¾›äº†æ™ºèƒ½é™çº§ï¼Œä½†æ‚¨å¯ä»¥æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µæ‰‹åŠ¨é…ç½®æœ€ä¼˜ç»„åˆï¼š

```json
{
  // ä¸»æ¨¡å‹ï¼šGPT-4 Turbo
  "aigitcommit.modelName": "gpt-4-turbo-preview",
  // Chunk æ¨¡å‹ï¼šæ ¹æ®æµ‹è¯•é€‰æ‹©æœ€ä¼˜
  "aigitcommit.chunkModel": "gpt-4o-mini"
}
```

## ç›¸å…³èµ„æº

- [é…ç½®æŒ‡å—](README.md) - æŸ¥çœ‹æ‰€æœ‰é…ç½®é€‰é¡¹
- [OpenAI é…ç½®](openai.md) - OpenAI æ¨¡å‹è¯¦ç»†é…ç½®
- [Gemini é…ç½®](gemini.md) - Google Gemini æ¨¡å‹é…ç½®
- [æ™ºèƒ½æ–‡ä»¶è¿‡æ»¤](smart-filter.md) - è¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½
- [æ•…éšœæ’é™¤](../troubleshooting.md) - è§£å†³å¸¸è§é—®é¢˜

---

## English

# Hybrid Model Strategy

## Overview

The Hybrid Model Strategy is a performance optimization feature that significantly reduces costs and processing time while maintaining output quality by using models with different performance characteristics when processing large code changes.


**Core Concept**: **"Fast Model for Reading (Map), Slow Model for Writing (Reduce)"**

- **Map Phase**: Use lightweight, fast models to process large numbers of diff chunks in parallel
- **Reduce Phase**: Use high-quality models to generate the final commit message

## Why Hybrid Model Strategy?

### Problem Scenario

When processing large commits (e.g., refactoring, feature development), traditional Map-Reduce implementations use the same primary model (e.g., GPT-4) in all phases, leading to:

- **High Costs**: Processing 20 chunks may consume 21 GPT-4 calls
- **Slow Speed**: Each chunk needs to wait for GPT-4 response
- **Resource Waste**: Simple summary tasks in Map phase don't need the most powerful model

### Solution

The Hybrid Model Strategy optimizes performance while ensuring quality through intelligent model selection:

| Phase | Task Complexity | Model Used | Reason |
|-------|----------------|------------|--------|
| Map | Low (generate chunk summaries) | Lightweight model | Fast, economical |
| Reduce | High (generate final commit message) | High-quality model | Ensure output quality |

## Performance and Cost Comparison

### Real Case: Processing 20 Chunks in Large Commit

#### Traditional Approach (All GPT-4)
```
Map Phase:    20 chunks Ã— GPT-4 = 20x cost, ~8 seconds
Reduce Phase: 1 time Ã— GPT-4 = 1x cost, ~2 seconds
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total Cost: 21x
Total Time: 10 seconds
```


#### Hybrid Model Strategy (Map uses gpt-4o-mini)
```
Map Phase:    20 chunks Ã— gpt-4o-mini = 2x cost, ~4 seconds
Reduce Phase: 1 time Ã— GPT-4 = 1x cost, ~2 seconds
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total Cost: 3x
Total Time: 6 seconds

ğŸ’° Cost Savings: 85.7%
âš¡ Time Savings: 40%
```

## Recommended Lightweight Models

### OpenAI Series

#### gpt-4o-mini
- **Relative Cost**: 10% of GPT-4
- **Relative Speed**: 2x faster
- **Use Cases**: Map phase, chunk summaries, fast processing
- **Recommendation**: â­â­â­â­â­

#### gpt-3.5-turbo
- **Relative Cost**: 5% of GPT-4
- **Relative Speed**: 2.5x faster
- **Use Cases**: Budget priority, simple projects
- **Recommendation**: â­â­â­â­

### Google Gemini Series

#### gemini-1.5-flash
- **Relative Cost**: 5% of Gemini Pro
- **Relative Speed**: 3x faster
- **Use Cases**: Map phase, ultra-fast processing, free tier
- **Recommendation**: â­â­â­â­â­

### Model Selection Guide

| Primary Model | Recommended Chunk Model | Cost Savings | Speed Improvement |
|--------------|------------------------|--------------|-------------------|
| GPT-4 | gpt-4o-mini | ~85% | ~40% |
| GPT-4 Turbo | gpt-4o-mini | ~85% | ~40% |
| GPT-4o | gpt-4o-mini | ~80% | ~35% |
| Gemini Pro | gemini-1.5-flash | ~90% | ~50% |
| Gemini 1.5 Pro | gemini-1.5-flash | ~90% | ~50% |


## Configuration Methods

### Method 1: Using Configuration Wizard (Recommended)

1. Open Command Palette: `Ctrl+Shift+P` (Windows/Linux) or `Cmd+Shift+P` (Mac)
2. Type and select: `AI Git Commit: Configure Settings`
3. Follow the wizard to complete configuration
4. Select lightweight model in "Chunk Model" option

### Method 2: Direct Configuration File Editing

Open VSCode settings (`Ctrl+,`), search for "AI Git Commit", find "Chunk Model" configuration:

```json
{
  "aigitcommit.provider": "openai",
  "aigitcommit.modelName": "gpt-4",
  "aigitcommit.chunkModel": "gpt-4o-mini",
  "aigitcommit.enableMapReduce": true
}
```

### Configuration Examples

#### Example 1: OpenAI Hybrid Strategy
```json
{
  "aigitcommit.provider": "openai",
  "aigitcommit.modelName": "gpt-4",
  "aigitcommit.chunkModel": "gpt-4o-mini",
  "aigitcommit.enableMapReduce": true,
  "aigitcommit.maxTokens": 500
}
```

#### Example 2: Gemini Hybrid Strategy
```json
{
  "aigitcommit.provider": "gemini",
  "aigitcommit.modelName": "gemini-1.5-pro",
  "aigitcommit.chunkModel": "gemini-1.5-flash",
  "aigitcommit.enableMapReduce": true
}
```


#### Example 3: Using Smart Downgrade (Leave chunkModel Empty)
```json
{
  "aigitcommit.provider": "openai",
  "aigitcommit.modelName": "gpt-4",
  "aigitcommit.chunkModel": "",
  "aigitcommit.enableMapReduce": true
}
```
When `chunkModel` is left empty, the system automatically selects an appropriate lightweight model.

## Smart Downgrade Mechanism

### What is Smart Downgrade?

When you don't configure `chunkModel`, the system automatically selects an appropriate lightweight model based on your primary model. This is a zero-configuration optimization solution.

### Downgrade Rules

| Primary Model | Auto Downgrade To | Trigger Condition |
|--------------|-------------------|-------------------|
| gpt-4 | gpt-4o-mini | Model name contains "gpt-4" and is not "gpt-4o-mini" |
| gpt-4-turbo | gpt-4o-mini | Same as above |
| gpt-4o | gpt-4o-mini | Same as above |
| gpt-4-32k | gpt-4o-mini | Same as above |
| gemini-pro | gemini-1.5-flash | Model name is "gemini-pro" |
| gemini-1.5-pro | gemini-1.5-flash | Model name is "gemini-1.5-pro" |
| Other models | Keep original | Not in downgrade mapping |

### Workflow

```
Start Map-Reduce Processing
    â†“
Check chunkModel Configuration
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Configured?     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ Yes            â†“ No
Use Configured    Apply Smart Downgrade
    â†“                  â†“
Validate Model    Validate Model
    â†“                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Available?      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ Yes            â†“ No
Use Selected      Fallback to Primary
    â†“                  â†“
Map Phase         Map Phase
    â†“                  â†“
Reduce Phase (Use Primary Model)
```


### Special Cases

#### Local Models (Ollama, LM Studio, etc.)

Local models **do not trigger smart downgrade** because:
- Local models are usually free
- Users may only have one model configured
- Downgrade may cause model unavailability

```json
{
  "aigitcommit.provider": "ollama",
  "aigitcommit.modelName": "llama2",
  "aigitcommit.chunkModel": "",  // Won't downgrade, continues using llama2
  "aigitcommit.enableMapReduce": true
}
```

#### Already Lightweight Model

If the primary model is already lightweight (e.g., gpt-4o-mini), the system keeps using it:

```json
{
  "aigitcommit.provider": "openai",
  "aigitcommit.modelName": "gpt-4o-mini",
  "aigitcommit.chunkModel": "",  // Keeps using gpt-4o-mini
  "aigitcommit.enableMapReduce": true
}
```

## Best Practices

### 1. Choose Strategy Based on Project Size

#### Small Projects (< 5 file changes)
- **Recommendation**: Don't enable Map-Reduce, use primary model directly
- **Reason**: Small changes don't need chunking, hybrid strategy advantages not significant

```json
{
  "aigitcommit.enableMapReduce": false
}
```

#### Medium Projects (5-20 file changes)
- **Recommendation**: Enable hybrid strategy, use smart downgrade
- **Configuration**: Leave `chunkModel` empty, let system auto-select

```json
{
  "aigitcommit.enableMapReduce": true,
  "aigitcommit.chunkModel": ""
}
```


#### Large Projects (> 20 file changes)
- **Recommendation**: Enable hybrid strategy, explicitly configure lightweight model
- **Configuration**: Choose optimal chunk model based on primary model

```json
{
  "aigitcommit.provider": "openai",
  "aigitcommit.modelName": "gpt-4",
  "aigitcommit.chunkModel": "gpt-4o-mini",
  "aigitcommit.enableMapReduce": true
}
```

### 2. Balance Cost and Quality

#### Pursue Ultimate Cost Optimization
```json
{
  "aigitcommit.provider": "gemini",
  "aigitcommit.modelName": "gemini-1.5-pro",
  "aigitcommit.chunkModel": "gemini-1.5-flash"
}
```
- Cost savings: ~90%
- Suitable for: Individual developers with limited budget

#### Balance Cost and Quality
```json
{
  "aigitcommit.provider": "openai",
  "aigitcommit.modelName": "gpt-4",
  "aigitcommit.chunkModel": "gpt-4o-mini"
}
```
- Cost savings: ~85%
- Suitable for: Most teams and projects

#### Pursue Ultimate Quality
```json
{
  "aigitcommit.provider": "openai",
  "aigitcommit.modelName": "gpt-4",
  "aigitcommit.chunkModel": "gpt-4"
}
```
- Cost savings: 0% (but still has speed advantage)
- Suitable for: Critical projects with extremely high quality requirements


## Troubleshooting

### Issue 1: Chunk Model Unavailable

**Symptom**: Log shows "Chunk model unavailable, falling back to primary model"

**Causes**:
- Configured chunk model doesn't exist
- API key doesn't have access to the model
- Model name spelling error

**Solutions**:
1. Check if model name is correct
2. Verify API key permissions
3. Try using smart downgrade (leave `chunkModel` empty)

```json
{
  "aigitcommit.chunkModel": ""  // Use smart downgrade
}
```

### Issue 2: No Cost Savings Observed

**Symptom**: No significant cost reduction after using hybrid strategy

**Possible Causes**:
- Map-Reduce not enabled
- Changes too small, didn't trigger chunking
- Chunk model configured same as primary model

**Solutions**:
1. Confirm Map-Reduce is enabled:
```json
{
  "aigitcommit.enableMapReduce": true
}
```

2. Confirm chunk model is lightweight:
```json
{
  "aigitcommit.chunkModel": "gpt-4o-mini"  // Don't set to "gpt-4"
}
```

3. Check output logs to confirm model usage


### Issue 3: Quality Degradation

**Symptom**: Commit message quality worse than before after using hybrid strategy

**Analysis**:
- Map phase summary quality affects final result
- Some lightweight models may not suit your project

**Solutions**:
1. Try more powerful chunk model:
```json
{
  "aigitcommit.chunkModel": "gpt-4o-mini"  // Upgrade from gpt-3.5-turbo
}
```

2. Or use primary model for both Map and Reduce:
```json
{
  "aigitcommit.chunkModel": "gpt-4"  // Same as primary model
}
```

3. Adjust temperature parameter for more consistent output:
```json
{
  "aigitcommit.temperature": 0.5  // Lower creativity, higher consistency
}
```

## FAQ

### Q1: Will hybrid model strategy affect commit message quality?

**A**: No. The Reduce phase (generating final commit message) always uses your configured primary model (e.g., GPT-4), ensuring output quality. The Map phase only generates simple chunk summaries, which lightweight models can handle well.

### Q2: Must I manually configure chunkModel?

**A**: Not required. If you leave `chunkModel` empty, the system automatically selects an appropriate lightweight model based on your primary model (smart downgrade). This is the recommended zero-configuration approach.


### Q3: Can local models (Ollama) use hybrid strategy?

**A**: Yes, but not recommended. Local models are usually free, so the cost advantage of hybrid strategy is not significant. Also, you may only have one local model configured, and downgrade may cause unavailability. The system automatically skips smart downgrade for local models.

### Q4: Is hybrid strategy useful for small commits?

**A**: Not very useful. Small commits (< 5 files) usually don't trigger Map-Reduce chunking, so hybrid strategy advantages can't be realized. Recommended to enable for large commits.

### Q5: Can I use a more powerful model in Map phase?

**A**: Yes. You can set `chunkModel` to the same as or even more powerful than the primary model. But this loses cost and speed advantages.

### Q6: Will smart downgrade update automatically?

**A**: Yes. When you change the primary model, smart downgrade automatically selects an appropriate lightweight model based on the new primary model. No manual adjustment needed.

### Q7: How to verify hybrid strategy is working?

**A**: Check VSCode's Output panel ("AI Git Commit" channel), which will show:
```
[Hybrid Model Strategy] Map phase using model: gpt-4o-mini
[Hybrid Model Strategy] Reduce phase using model: gpt-4
```

## Related Resources

- [Configuration Guide](README.md) - View all configuration options
- [OpenAI Configuration](openai.md) - Detailed OpenAI model configuration
- [Gemini Configuration](gemini.md) - Google Gemini model configuration
- [Smart File Filter](smart-filter.md) - Further optimize performance
- [Troubleshooting](../troubleshooting.md) - Solve common issues
